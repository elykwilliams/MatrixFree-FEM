\documentclass[svgnames]{beamer} % for xcolor https://latex.org/forum/viewtopic.php?t=2445 
\mode<presentation>
{
\usetheme{Warsaw}
\setbeamertemplate{page number in head/foot}[totalframenumber]
%\setbeamertemplate{footline}[frame number]
\setbeamertemplate{headline}{}
\setbeamercovered{transparent}
% or whatever (possibly just delete it)
}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}

\title{Matrix-free finite element method}
\institute[UH] {
	\includegraphicsw[.3]{logo_uh.png}
}
\date[December 10, 2019]{COSC\,6365 Final Project, December 10, 2019}

% bold for everything
\usepackage{bm}
% lowercase mathcal font
\usepackage{dutchcal}
\hypersetup{
	colorlinks,
	allcolors=.,
	urlcolor=blue,
	filecolor=blue
}
% braces for subeqns and boxes
\usepackage{empheq}
% http://mirror.hmc.edu/ctan/macros/latex/contrib/mathtools/empheq.pdf
\newcommand*\widefbox[1]{\fbox{\hspace{1em}#1\hspace{1em}}}
% hl
\usepackage{soul}
\makeatletter
\let\HL\hl
\renewcommand\hl{%
	\let\set@color\beamerorig@set@color
	\let\reset@color\beamerorig@reset@color
	\HL}
\makeatother
% sub figures / grids of pictures
\usepackage{subcaption} 
\graphicspath{{./img/}} % includegraphics path
\newcommand{\includegraphicsw}[2][1.]{\includegraphics[width=#1\linewidth]{#2}}
\newcommand{\svginput}[1]{\input{img/#1}} % pdf_tex path
\newcommand{\svginputw}[2][1.]{\def\svgwidth{#1\linewidth}\input{./img/#2}} % pdf_tex path
% tables
\let\oldtabular\tabular
\renewcommand{\tabular}[1][1.5]{\def\arraystretch{#1}\oldtabular}
\usepackage{hhline}
\usepackage{multirow}
% \coloneqq
\usepackage{mathtools}
% math commands for convinience
\DeclareMathOperator{\argmin}{arg\,min}
% bold vectors
\newcommand{\vect}[1]{\boldsymbol{\mathbf{#1}}}

\newcommand{\bcell}{T}
\newcommand{\bmesh}{{\vect{\mathcal T}}}
\newcommand{\mmesh}{{\vect{\mathcal \tau}}}
\newcommand{\bfaces}[1][]{{\vect{\mathcal F}_{\text{#1}}}}
\newcommand{\mfaces}[1][]{{\vect{\mathcal f}_{\text{#1}}}}

%\newcommand{\LTwo}{{\mathbb L^2}}
%\newcommand{\lTwo}{{\mathcal l^2}}
%\newcommand{\HDiv}{{\mathbb H_\text{div}}}
%\newcommand{\Rn}[1]{{\mathbb R^{#1}}}
%\newcommand{\Pn}[1]{{\mathbb P^{#1}}}
%\newcommand{\LTwoSpace}[1][\Omega]{{\mathbb L^2\left({#1}\right)}}
%\newcommand{\HSpace}[1]{{\mathbb H^{#1}\left(\Omega\right)}}
%\newcommand{\lTwoSpace}[1][\Omega]{{\mathcal l^2\left({#1}\right)}}
%\newcommand{\HDivSpace}[1][\Omega]{{\mathbb H_\text{div}\left({#1}\right)}}
%\newcommand{\PnSpace}[2]{{\mathbb P^{#1}\left({#2}\right)}}

% precond
\newcommand{\Pbd}{\mathbcal P_{\text{BD}}}
\newcommand{\Pbt}{\mathbcal P_{\text{BT}}}
\newcommand{\Pmg}{\vect P_{\text{MG}}}
\newcommand{\Pmgv}{\vect P_{\text{MG(V)}}}
\newcommand{\Pilu}{\vect P_{\text{ILU(0)}}}

\newcommand{\USpace}{\mathbb{\vect U}}
\newcommand{\PSpace}{\mathbb P}
\usepackage{dutchcal} % lowercase mathcal font
\newcommand{\aForm}[2]{\mathbcal a(#1, #2)}
\newcommand{\bForm}[2]{\mathbcal b(#1, #2)}
\newcommand{\lForm}[1]{\mathbcal l(#1)}
\newcommand{\LSpace}{\mathbb L^2}
\newcommand{\HSpace}{\mathbb H^1}

% differentials
\newcommand*\diff{\mathop{}\!\mathrm{d}}
\newcommand*\Diff[1]{\mathop{}\!\mathrm{d^#1}}

\usepackage{listings}
\definecolor{mygreen}{rgb}{0,0.6,0}
\lstset{
	%	language=C++,
	%	basicstyle=\footnotesize\ttfamily,
	breaklines=true,
	%	commentstyle=\color{mygreen},
	frame=l,
	xleftmargin=5pt,
	tabsize=2,
	%	belowskip=-1pt
} 

\begin{document}

	\author[K. Williams, A. Zhiliakov]{%
		\begin{tabular}[1.]{cc}
			Kyle Williams & Alexander Zhiliakov \\
			\href{mailto:kylew@math.uh.edu}{kylew@math.uh.edu} & \href{mailto:alex@math.uh.edu}{alex@math.uh.edu}
		\end{tabular}
		\vskip -1mm
	}

	\begin{frame}
		\titlepage
	\end{frame}

%	\begin{frame}{Overview}
%		\tableofcontents
%	\end{frame}
%	
%	\section{Theoretical background}

	\begin{frame}{Finite element method workflow \& motivation}
		\begin{enumerate}
			\item $L\,u = f$ + BCs $\Rightarrow$ Time discretization, linearization and finite element approximation $\Rightarrow$ Linear system~$\vect A\,\vect x = \vect b$ with \textbf{stiffness matrix}~$\vect A \in \mathbb R^{n\times n}$
			\item For~$L = -\nabla\cdot(\vect K\,\nabla)$ we have~$\vect A_{ij} = \int \vect K\,\nabla\phi_j\cdot\nabla\phi_i$ with $\phi_i$ being a basis function with a compact support; $\phi_i$ is typically chosen as a piecewise polynomial of degree~$k$.
		\end{enumerate}
		\begin{figure}
			\begin{subfigure}{.5\linewidth}
				\centering
				\includegraphicsw[.8]{sparse.pdf}
				{Nonzero pattern of~$\vect A$}
			\end{subfigure}%
			\begin{subfigure}{.5\linewidth}
				$\vect A$ is \textbf{sparse}, \\i.e. it requires~$O(n)$ memory resources and $O(n)$ FLOPs when multiplying the matrix by a vector. 
			\end{subfigure}
		\end{figure}
	\end{frame}

	\begin{frame}{Stiffness matrix assembly}
		\begin{itemize}
		\item For large complex problems, especially in 3D, it is typical to use an iterative solver with a suitable preconditioner to solve the system
		\item The core operation is~$\vect x \mapsto \vect A\,\vect x \eqqcolon \vect z$
		\item Hence it is crucially important that the sparse matrix-vector multiplication is implemented efficiently.
		\end{itemize}
		\begin{figure}

			\begin{subfigure}{.45\linewidth}
				\centering
				\includegraphicsw[.8]{mesh.png}
				Domain mesh
			\end{subfigure}%
			\begin{subfigure}{.55\linewidth}
				$\vect A$ is assembled from small cell matrices~$\vect A_\text{cell} \in \mathbb R^{k^{\text{dim}}\times k^{\text{dim}}}$. Formally it can be written as
				$$
					\vect A = \sum \vect P^T_\text{cell}\,\vect A_\text{cell}\,\vect P_\text{cell},
				$$
				where rectangular matrix~$\vect P_\text{cell}$ connect local cell d.o.f. to global mesh ones.
			\end{subfigure}
		\end{figure}
	\end{frame}	

	\begin{frame}[fragile]{Sparse matrix-vector multiplication}
		It is very common that $\vect A$ is represented in CSR format. In this case multiplication takes the form:
		\begin{lstlisting}[basicstyle=\small]
			for (i = 0; i < nrows; ++i) 
				for (k = rowptr[i]; k < rowptr[i+1]; ++k)
					z[i] += val[k] * x[colind[k]];
		\end{lstlisting}
		CSR is optimal in the sense that both storage and multiplication require~$O(n)$ resources. However,
		\begin{enumerate}
			\item there is no spatial locality for~$\vect x$, and
			\item there are 5 memory refs vs. 2 arithmetic operations, i.e. the routine is memory bandwidth bounded
		\end{enumerate}
	\end{frame}	
	
	\begin{frame}{Matrix-free approach: Idea}
	The alternative approach is \textbf{matrix-free} implementation: Do not store the big sparse matrix~$\vect A$ but compute the action of its cell matrices~$\vect A_\text{cell}$ on the fly.
		\begin{enumerate}
			\item Low arithmetic intensity is the bottleneck for matrix-based computations; Matrix-free evaluation that reads less data can be advantageous even if it does more computations
			\item Matrix-free methods have a better complexity per degree of freedom:~$O(k)$ vs.~$O(k^\text{dim})$ for matrix-based methods ($k$ is basis func degree); This makes it attractive for higher order elements $k > 1$ and dim = 3~\includegraphics[width=12px]{clown.png}
		\end{enumerate}
	\end{frame}	
	
	\begin{frame}{Matrix-free approach: Implementation}
		Our aim is to rewrite
		$$
			\vect x \mapsto \vect A\,\vect x = \big(\sum \vect P^T_\text{cell}\,\vect A_\text{cell}\,\vect P_\text{cell}\big)\vect x = \sum \vect P^T_\text{cell}\,\vect A_\text{cell}\,\vect x_\text{cell}
		$$
		w/o storing local matrices~$\vect A_\text{cell}$. Note that
		$$
			\vect A_{\text{cell}\,ij} = \int_\text{ref\_cell} \vect K_\text{ref\_cell}\,(\vect J^{-T}_\text{cell}\,\nabla\phi_{\text{ref\_cell}\,j})\cdot(\vect J^{-T}_\text{cell}\,\nabla\phi_{\text{ref\_cell}\,i})\,|\text{det}\,
			\vect J|
		$$
		can be rewritten as
		$$
			\vect A_\text{cell}\,\vect x_\text{cell} = \vect B^{T}_\text{ref\_cell}\,\vect J^{-1}_\text{cell}\,\vect D_\text{cell}\,\vect J^{-T}_\text{cell}\,\vect B_\text{ref\_cell}\,\vect x_\text{cell}
		$$
		with \textbf{fixed} gradient mtx~$\vect B_\text{ref\_cell}$, reference-to-physical cell transformation~$\vect J_\text{cell}$, and diagonal diffusion mtx~$D_\text{cell}$. This gives us
		\begin{itemize}
			\item computation of~$\vect A_\text{cell}$ on the fly via applying matrix-vector products repeatedly, and
			\item $O(k)$ complexity per degree of freedom
		\end{itemize}
	\end{frame}	

	\begin{frame}{Execution time}
		We stick to a 3D diffusion problem, $L = -\nabla\cdot(\vect K\,\nabla)$, with~$k = 3$. Our measurements are based on 5 matrix-vector multiplications per run on \href{https://portal.tacc.utexas.edu/user-guides/stampede2}{TAAC} skx-normal partition node (2 sockets, 48 cores, 96 threads)
		\begin{figure}
			\centering
			\begin{subfigure}{.5\linewidth}
				\centering\small{CSR}
				\includegraphicsw{clTime.pdf}
			\end{subfigure}%
			\begin{subfigure}{.5\linewidth}
				\centering\small{Matrix-free}
				\includegraphicsw{mfTime.pdf}
			\end{subfigure}%
			\vskip .5cm
			\begin{subfigure}{.8\linewidth}
				\centering\small{Best thread team sizes}
				\vskip .3cm
				\includegraphicsw{bestTime.pdf}
			\end{subfigure}
		\end{figure}
	\end{frame}

	\begin{frame}{Other statistics}
		\begin{figure}
			\centering\small{Cache miss ratio (left) and instructions per cycle (right) for the largest matrix size~$n = 912\,673$}
			\vskip .3cm
			\begin{subfigure}{.5\linewidth}
				\includegraphicsw{cache.pdf}
			\end{subfigure}%
			\begin{subfigure}{.5\linewidth}
				\includegraphicsw{inst.pdf}
			\end{subfigure}%
			\vskip .5cm
			\begin{subfigure}{.8\linewidth}
				\centering\small{Energy consumption for a single thread; TDP = 150\,W}
				\vskip .3cm
				\includegraphicsw{rapl.pdf}
			\end{subfigure}
		\end{figure}
	\end{frame}	
	
	\begin{frame}{Summary}
		Matrix-free vs. CSR matrix-vector multiplication approaches: 
		\begin{itemize}
			\item We see that the matrix-free approach scales well as one increases the number of threads, and CSR does not; Moreover,
			\item its inst/cycle ratio decays linearly (not the case for CSR!), and \% of cache misses decreases from 31 to 20 (vs. 41 to 34 for CSR). For the largest mtx size its execution time turns out to be $>2$ times better than ditto for CSR approach.
			\item The energy consumption is quite comparable; Matrix-free approach spends slightly more energy on CPU than CSR approach.
			\item This confirms that the matrix-free approach is much less memory bandwidth bounded than CSR.
			\item Some drawbacks: Constructing matrix-free preconditioners is not straightforward; Implementation for more complicated stiffness matrices is not straightforward
		\end{itemize}
	\end{frame}
	
\end{document}


